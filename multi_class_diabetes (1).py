# -*- coding: utf-8 -*-
"""Multi class diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cm3s2C5CarfqdNa58_HWy8_8m5b3vqp3
"""

from google.colab import drive
drive.mount('/content/drive')

# For ignoring the warnings
import warnings
warnings.filterwarnings('ignore')

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Importing tha data
import pandas as pd
dataset = pd.read_csv('/content/drive/MyDrive/Project Databases/Edited(253k)Diabetes heath indicators dataet - (253k)Diabetes heath indicators dataet.csv')
dataset.head()

dataset.isnull().sum() # For null values

x = dataset.iloc[:,:-1]  # Data except last column
y = dataset.iloc[:,-1] # last column in data
x.head()

y.head()

dataset.corr()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(15, 15))  # Adjust the figsize as per your preference
sns.heatmap(dataset.corr(), fmt='.0%', annot=True)

plt.show()

import matplotlib.pyplot as plt

fig, ax = plt.subplots(nrows=13, ncols=2, figsize=(10, 30))
fig.tight_layout(pad=3.0)
ax[0,0].set_title('HighBP')
ax[0,0].hist(dataset.HighBP[dataset.Outcome==1]);
ax[0,1].set_title('HighChol')
ax[0,1].hist(dataset.HighChol[dataset.Outcome==1]);
ax[1,0].set_title('CholCheck')
ax[1,0].hist(dataset.CholCheck[dataset.Outcome==1]);
ax[1,1].set_title('BMI')
ax[1,1].hist(dataset.BMI[dataset.Outcome==1]);
ax[2,0].set_title('Smoker')
ax[2,0].hist(dataset.Smoker[dataset.Outcome==1]);
ax[2,1].set_title('Stroke')
ax[2,1].hist(dataset.Stroke[dataset.Outcome==1]);
ax[3,0].set_title('HeartDiseaseorAttack')
ax[3,0].hist(dataset.HeartDiseaseorAttack[dataset.Outcome==1]);
ax[3,1].set_title('PhysActivity')
ax[3,1].hist(dataset.PhysActivity[dataset.Outcome==1])
ax[4,0].set_title('Fruits')
ax[4,0].hist(dataset.Fruits[dataset.Outcome==1])
ax[4,1].set_title('Veggies')
ax[4,1].hist(dataset.Veggies[dataset.Outcome==1])
ax[5,0].set_title('HvyAlcoholConsump')
ax[5,0].hist(dataset.HvyAlcoholConsump[dataset.Outcome==1])
ax[5,1].set_title('AnyHealthcare')
ax[5,1].hist(dataset.AnyHealthcare[dataset.Outcome==1])
ax[6,0].set_title('NoDocbcCost')
ax[6,0].hist(dataset.NoDocbcCost[dataset.Outcome==1])
ax[6,1].set_title('GenHlth')
ax[6,1].hist(dataset.GenHlth[dataset.Outcome==1])
ax[7,0].set_title('MentHlth')
ax[7,0].hist(dataset.MentHlth[dataset.Outcome==1])
ax[8,1].set_title('PhysHlth')
ax[8,1].hist(dataset.PhysHlth[dataset.Outcome==1])
ax[9,0].set_title('DiffWalk')
ax[9,0].hist(dataset.DiffWalk[dataset.Outcome==1])
ax[10,1].set_title('Sex')
ax[10,1].hist(dataset.Sex[dataset.Outcome==1])
ax[11,0].set_title('Age')
ax[11,0].hist(dataset.Age[dataset.Outcome==1])
ax[11,1].set_title('Education')
ax[11,1].hist(dataset.DiffWalk[dataset.Outcome==1])
ax[12,0].set_title('Income')
ax[12,0].hist(dataset.Income[dataset.Outcome==1])

import seaborn as sns
import matplotlib.pyplot as plt

ax = sns.countplot(data=dataset, x='Outcome')

# Add numbers on top of the bars
for p in ax.patches:
    ax.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()),
                ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')

plt.show()

# For training and testing of model

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.1)

"""**K-Nearest Neighbour**"""

# K nearest neighbor model

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 23)
knn.fit(x_train,y_train)
predict1 = knn.predict(x_test)
predict1

y_test # Testing data of y

# For counting mis-classifies values

count_missclassified1 = (y_test!=predict1).sum()
count_missclassified1

# For finding the accuracy

from sklearn import metrics
accuracy1 = metrics.accuracy_score(y_test,predict1)
accuracy1*100

# Clssification report

c_f1 = metrics.classification_report(y_test,predict1)
print(c_f1)

from sklearn.metrics import confusion_matrix

# Obtain predictions from your model
predictions = knn.predict(x_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, predictions)

# Calculate sensitivity (true positive rate)
sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])

# Calculate specificity (true negative rate)
specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])

# Print sensitivity and specificity
print("Sensitivity:", sensitivity)
print("Specificity:", specificity)

from sklearn.metrics import cohen_kappa_score
predictions = knn.predict(x_test)
kappa = cohen_kappa_score(y_test, predictions)
print("Cohen's kappa value:", kappa)

# Testing with the value

n = [[1,1,1,30,1,0,1,0,1,1,0,1,0,5,30,30,1,0,9,5,1]]
pred1 = knn.predict(n)
pred1

"""**LOGISTIC REGRESSION**"""

# Analysing with Logistic regression

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(random_state=20,penalty='l2')
lr.fit(x_train,y_train)
predict2 = lr.predict(x_test)
predict2

# Counting mis-classified values for logistic regression

count_missclassified2 = (y_test!=predict2).sum()
count_missclassified2

# For finding the accuracy

accuracy2 = metrics.accuracy_score(y_test,predict2)
accuracy2*100

# Evaluating classification report
c_r2 = metrics.classification_report(y_test,predict2)
print(c_r2)

from sklearn.metrics import confusion_matrix

# Obtain predictions from your model
predictions = lr.predict(x_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, predictions)

# Calculate sensitivity (true positive rate)
sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])

# Calculate specificity (true negative rate)
specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])

# Print sensitivity and specificity
print("Sensitivity:", sensitivity)
print("Specificity:", specificity)

from sklearn.metrics import cohen_kappa_score
predictions = lr.predict(x_test)
kappa = cohen_kappa_score(y_test, predictions)
print("Cohen's kappa value:", kappa)

# Testing with the values

n = [[1,1,1,30,1,0,1,0,1,1,0,1,0,5,30,30,1,0,9,5,1]]
pred2 = lr.predict(n)
pred2# Testing with the values

"""**RANDOM FOREST ALGORITHM**"""

#Random Forest Algorithm

from sklearn import ensemble
rf = ensemble.RandomForestClassifier(n_estimators = 7,criterion = 'entropy',max_features = 5,random_state=20) #random forest model
rf.fit(x_train,y_train)
predict3 = rf.predict(x_test) #prediction
predict3

# Counting mis-classified values for logistic regression

count_missclassified3 = (y_test!=predict3).sum()
count_missclassified3

accuracy3 = metrics.accuracy_score(y_test,predict3)
accuracy3*100

# Evaluating classification report
c_r3 = metrics.classification_report(y_test,predict3)
print(c_r3)

from sklearn.metrics import confusion_matrix

# Obtain predictions from your model
predictions = rf.predict(x_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, predictions)

# Calculate sensitivity (true positive rate)
sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])

# Calculate specificity (true negative rate)
specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])

# Print sensitivity and specificity
print("Sensitivity:", sensitivity)
print("Specificity:", specificity)

from sklearn.metrics import cohen_kappa_score
predictions = rf.predict(x_test)
kappa = cohen_kappa_score(y_test, predictions)
print("Cohen's kappa value:", kappa)

# Testing with the values

n = [[1,1,1,30,1,0,1,0,1,1,0,1,0,5,30,30,1,0,9,5,1]]
pred3 = rf.predict(n)
pred3

"""**SVM**"""

# support vector machine SVM
from sklearn import svm

model = svm.SVC(probability=True)
model.fit(x_train,y_train)
predict4=model.predict(x_test)
predict4

# Counting mis-classified values for support vector machine SVM

count_missclassified4 = (y_test != predict4).sum()
count_missclassified4

"""GAUSSIAN NAIVE BAYES

"""

#Using Gaussian Naïve Bayes Classifier
from sklearn.naive_bayes import GaussianNB
model3 = GaussianNB()
model3.fit(x_train, y_train)
predict7 = model3.predict(x_test)
print(predict7)

# Counting mis-classified values for Gaussian Naïve Bayes Classifier

count_missclassified7 = (y_test != predict7).sum()
count_missclassified7

#calculating accuracy score
# Importing the necessary module
from sklearn import metrics
accuracy7 = metrics.accuracy_score(y_test,predict7)
accuracy7*100

# Clssification report

c_r7 = metrics.classification_report(y_test,predict7)
print(c_r7)

from sklearn.metrics import confusion_matrix

# Obtain predictions from your SVM model
predictions = model3.predict(x_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, predictions)

# Calculate sensitivity (true positive rate)
sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])

# Calculate specificity (true negative rate)
specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])

# Print sensitivity and specificity
print("Sensitivity:", sensitivity)
print("Specificity:", specificity)

from sklearn.metrics import cohen_kappa_score
predictions = model3.predict(x_test)
kappa = cohen_kappa_score(y_test, predictions)
print("Cohen's kappa value:", kappa)

"""ADA BOOST

"""

#using ada boost
import numpy as np
from sklearn.ensemble import AdaBoostClassifier
model4 = AdaBoostClassifier(n_estimators=10, learning_rate=0.01, random_state=0)
model4.fit(x_train, y_train)
predict8 = model4.predict(x_test)
print(predict8)

# Counting mis-classified values for ADA Boost

count_missclassified8 = (y_test != predict8).sum()
count_missclassified8

#calculating accuracy score
accuracy8 = metrics.accuracy_score(y_test,predict8)
accuracy8*100

# Clssification report

c_r8 = metrics.classification_report(y_test,predict8)
print(c_r8)

from sklearn.metrics import confusion_matrix

# Obtain predictions from your SVM model
predictions = model4.predict(x_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, predictions)

# Calculate sensitivity (true positive rate)
sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])

# Calculate specificity (true negative rate)
specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])

# Print sensitivity and specificity
print("Sensitivity:", sensitivity)
print("Specificity:", specificity)

from sklearn.metrics import cohen_kappa_score
predictions = model4.predict(x_test)
kappa = cohen_kappa_score(y_test, predictions)
print("Cohen's kappa value:", kappa)

"""GRADIANT BOOSTED MODEL"""

#Gradient Boosted Model
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier
model5 = GradientBoostingClassifier(n_estimators=10, learning_rate=0.01, random_state=0)
model5.fit(x_train, y_train)
predict9 = model5.predict(x_test)
print(predict9)

# Counting mis-classified values for Gradient Boosted Model

count_missclassified8 = (y_test != predict9).sum()
count_missclassified8

#calculating accuracy score
accuracy9 = metrics.accuracy_score(y_test,predict9)
accuracy9*100

# Clssification report

c_r9 = metrics.classification_report(y_test,predict9)
print(c_r9)

from sklearn.metrics import confusion_matrix

# Obtain predictions from your SVM model
predictions = model5.predict(x_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, predictions)

# Calculate sensitivity (true positive rate)
sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])

# Calculate specificity (true negative rate)
specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])

# Print sensitivity and specificity
print("Sensitivity:", sensitivity)
print("Specificity:", specificity)

from sklearn.metrics import cohen_kappa_score
predictions = model5.predict(x_test)
kappa = cohen_kappa_score(y_test, predictions)
print("Cohen's kappa value:", kappa)

"""XG BOOST"""

#Using XG Boost
import xgboost as xgb
model2 = xgb.XGBClassifier(n_estimators=16, learning_rate=0.01, max_depth=3)
model2.fit(x_train, y_train)
predict6 = model2.predict(x_test)
predict6

#No. Of Missclassified
count_missclassified6 = (y_test != predict6).sum()
count_missclassified6

#calculating accuracy score
accuracy6 = metrics.accuracy_score(y_test,predict6)
accuracy6*100

# Clssification report

c_r6 = metrics.classification_report(y_test,predict6)
print(c_r6)

from sklearn.metrics import confusion_matrix

# Obtain predictions from your SVM model
predictions = model2.predict(x_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, predictions)

# Calculate sensitivity (true positive rate)
sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])

# Calculate specificity (true negative rate)
specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])

# Print sensitivity and specificity
print("Sensitivity:", sensitivity)
print("Specificity:", specificity)

from sklearn.metrics import cohen_kappa_score
predictions = model2.predict(x_test)
kappa = cohen_kappa_score(y_test, predictions)
print("Cohen's kappa value:", kappa)

"""DECISION TREE

"""

# Using Decision Tree model

from sklearn import tree
dtree = tree.DecisionTreeClassifier(criterion = 'entropy',max_depth=1,min_samples_split=7)
dtree.fit(x_train,y_train)
predict5 = dtree.predict(x_test)
predict5

# Counting mis-classified values for Decision Tree Algorithm

count_missclassified5 = (y_test != predict5).sum()
count_missclassified5

# Finding the accuracy

accuracy5 = metrics.accuracy_score(y_test,predict5)
accuracy5*100

# Clssification report

c_r5 = metrics.classification_report(y_test,predict5)
print(c_r5)

from sklearn.metrics import confusion_matrix

# Obtain predictions from your SVM model
predictions = dtree.predict(x_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, predictions)

# Calculate sensitivity (true positive rate)
sensitivity = cm[1, 1] / (cm[1, 0] + cm[1, 1])

# Calculate specificity (true negative rate)
specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])

# Print sensitivity and specificity
print("Sensitivity:", sensitivity)
print("Specificity:", specificity)

from sklearn.metrics import cohen_kappa_score
predictions = dtree.predict(x_test)
kappa = cohen_kappa_score(y_test, predictions)
print("Cohen's kappa value:", kappa)

"""COMPARISON"""

import pandas as pd
import matplotlib.pyplot as plt

model_compare = pd.DataFrame({
    "KNN": accuracy1 * 100,
    "Logistic Regression": accuracy2 * 100,
    "Random Forest Classifier": accuracy3 * 100,
    "Decision Tree Algorithm": accuracy5 * 100,
    "XG Boost": accuracy6 * 100,
    "Gaussian Naive Bayes": accuracy7 * 100,
    "ADA Boost Model": accuracy8 * 100,
    "Gradient Boosted Model": accuracy9 * 100
}, index=["accuracy"])

model_compare.T.plot.bar(figsize=(15, 10))

for i in range(len(model_compare)):
    text = "{:.2f}%".format(model_compare.iloc[i, 0])
    plt.annotate(text, (i, model_compare.iloc[i, 0]), ha="center", va="bottom")

plt.show()

# Hypertuning LR
from sklearn.model_selection import GridSearchCV
import numpy as np
lr_params = [{'C': np.logspace(-4,4,30), "solver":["liblinear"]}]
clf = GridSearchCV(lr,lr_params,cv = 5,verbose=True) #grid search cv model creation
clf.fit(x_train,y_train)
score=clf.score(x_test,y_test)
print(score*100)

y_prediction=clf.predict(x_test)
y_prediction

sns.set(font_scale=2)
import seaborn as sns
from sklearn.metrics import confusion_matrix
sns.heatmap(confusion_matrix(y_test,y_prediction), annot=True,cbar=False, fmt='g')
plt.xlabel("True label")
plt.ylabel("Predicted label");

# from sklearn.metrics import accuracy_score
print(metrics.accuracy_score(y_test,y_prediction))

print(metrics.classification_report(y_test, y_prediction))

